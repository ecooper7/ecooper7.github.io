<html>
  <head>
    <title>Erica Cooper</title>
  </head>
  <body>
    <h1>Erica Cooper</h1>
    <h2>クーパー・エリカ</h2>

    Last update: 2024-04-01 (created page)

    <h3>About</h3>

    I completed the Ph.D. degree at Columbia University in the City of New York in 2019 with a research focus on text-to-speech synthesis for low-resource languages. I worked at the National Institute of Informatics in Tokyo, Japan from February 2019 - March 2024 as a contributor on the JST-ANR CREST VoicePersonae project. 
    I am currently working at the <a href=https://www.nict.go.jp/en/index.html>National Institute of Information and Communications Technology (NICT)</a> in Kyoto, Japan.  My research interests include speech and audio processing and synthesis, 
    and I was a co-organizer of the VoiceMOS Challenge in <a href=https://voicemos-challenge-2022.github.io/>2022</a> and <a href=https://voicemos-challenge-2023.github.io/>2023</a>.

    <ul>
    <li><a href=https://researchmap.jp/ecooper?lang=en>Researchmap</a></li>
    <li><a href=https://scholar.google.com/citations?user=_PCmoGcAAAAJ>Google Scholar</a></li>
    <li><a href=http://twitter.com/erica_cooper>Twitter</a></li>
    </li><a href=https://github.com/ecooper7>Github</a></li>
    </ul>

    <h3>Work and education history</h3>

    <ul>
      <li>2024-04 to present: Senior Researcher, Universal Communication Research Institute, National Institute of Information and Communications Technology</li>
      <li>2019-02 to 2024-03: Postdoctoral Researcher, Digital Content and Media Sciences Research Division, National Institute of Informatics</li>
      <li>2010-09 to 2019-02: PhD student, Department of Computer Science, Columbia University</li>
      <li>2012-06 to 2012-08: Software Engineering Intern, Google UK Ltd., London</li>      
      <li>2011-06 to 2011-08: Software Engineering Intern, Google Inc., NYC</li>      
      <li>2010-06 to 2010-08: Software Engineering Intern, Google Inc., NYC</li>
      <li>2009-09 to 2010-05: MEng student, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology</li>
      <li>2009-06 to 2009-08: Software Engineering Intern, Google Inc., NYC </li>
      <li>2005-09 to 2009-05: Bachelor student, Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology</li>
    </ul>

    <h3>Peer-reviewed publications</h3>

<b>Joint speaker encoder and neural back-end model for fully end-to-end automatic speaker verification with multiple enrollment utterances.</b> 
Chang Zeng, Xiaoxiao Miao, Xin Wang, Erica Cooper, Junichi Yamagishi
Computer Speech & Language, 86 101619-101619, Jun, 2024
	  
<b>The VoiceMOS Challenge 2023: Zero-shot Subjective Speech Quality Prediction for Multiple Domains.</b> 
Erica Cooper, Wen-Chin Huang, Yu Tsao, Hsin-Min Wang, Tomoki Toda, Junichi Yamagishi
ASRU 2023, Dec, 2023
	  
<b>Partial Rank Similarity Minimization Method for Quality MOS Prediction of Unseen Speech Synthesis Systems in Zero-Shot and Semi-supervised setting.</b> 
Hemant Yadav, Erica Cooper, Junichi Yamagishi, Sunayana Sitaram, Rajiv Ratn Shah
ASRU 2023, Dec, 2023
	  
<b>Exploring Isolated Musical Notes as Pre-training Data for Predominant Instrument Recognition in Polyphonic Music.</b> 
Lifan Zhong, Erica Cooper, Junichi Yamagishi, Nobuaki Minematsu
APSIPA ASC 2023, Oct, 2023
	  
<b>Investigating Range-Equalizing Bias in Mean Opinion Score Ratings of Synthesized Speech.</b> 
Erica Cooper, Junichi Yamagishi
Interspeech 2023, Aug, 2023
	  
<b>SASPEECH: A Hebrew Single Speaker Dataset for Text to Speech and Voice Conversion.</b> 
Orian Sharoni, Roee Shenberg, Erica Cooper
Interspeech 2023, Aug, 2023
	  
<b>Range-Based Equal Error Rate for Spoof Localization.</b> 
Lin Zhang, Xin Wang, Erica Cooper, Nicholas Evans, Junichi Yamagishi
Interspeech 2023, Aug, 2023
	  
<b>Improving Generalization Ability of Countermeasures for New Mismatch Scenario by Combining Multiple Advanced Regularization Terms</b> 
Chang Zeng, Xin Wang, Xiaoxiao Miao, Erica Cooper, Junichi Yamagishi
Interspeech 2023, Aug, 2023
	  
<b>Can Knowledge of End-to-End Text-to-Speech Models Improve Neural MIDI-to-Audio Synthesis Systems?</b> 
Xuan Shi, Erica Cooper, Xin Wang, Junichi Yamagishi, Shrikanth Narayanan
Submitted to ICASSP 2023, Jun, 2023
	  
<b>Speaker Anonymization using Orthogonal Householder Neural Network.</b> 
Xiaoxiao Miao, Xin Wang, Erica Cooper, Junichi Yamagishi, Natalia Tomashenko
IEEE/ACM Transactions on Audio, Speech, and Language Processing, 1-15, 2023	  
	  
<b>The PartialSpoof Database and Countermeasures for the Detection of Short Fake Speech Segments Embedded in an Utterance.</b> 
Lin Zhang, Xin Wang, Erica Cooper, Nicholas Evans, Junichi Yamagishi
IEEE/ACM Transactions on Audio, Speech, and Language Processing, 31 813-825, 2023
	  
<b>Analyzing Language-Independent Speaker Anonymization Framework under Unseen Conditions.</b> 
Xiaoxiao Miao, Xin Wang, Erica Cooper, Junichi Yamagishi, Natalia Tomashenko
Interspeech 2022, Sep, 2022	  
	  
<b>The VoiceMOS Challenge 2022.</b> 
Wen-Chin Huang, Erica Cooper, Yu Tsao, Hsin-Min Wang, Tomoki Toda, Junichi Yamagishi
Interspeech 2022, Sep, 2022 
	  
<b>Language-Independent Speaker Anonymization Approach using Self-Supervised Pre-Trained Models.</b> 
Xiaoxiao Miao, Xin Wang, Erica Cooper, Junichi Yamagishi, Natalia Tomashenko
Odyssey 2022: The Speaker and Language Recognition Workshop, Jun, 2022
	  
<b>Attention Back-End for Automatic Speaker Verification with Multiple Enrollment Utterances.</b> 
Chang Zeng, Xin Wang, Erica Cooper, Xiaoxiao Miao, Junichi Yamagishi
ICASSP 2022, May, 2022
	  
<b>On the Interplay Between Sparsity, Naturalness, Intelligibility, and Prosody in Speech Synthesis.</b> 
Cheng-I Lai, Erica Cooper, Yang Zhang, Shiyu Chang, Kaizhi Qian, Yi-Lun Liao, Yung-Sung Chuang, Alexander Liu, Junichi Yamagishi, David Cox …
ICASSP 2022, May, 2022
	  
<b>LDNet: Unified Listener Dependent Modeling in MOS Prediction for Synthetic Speech.</b> 
Wen-Chin Huang, Erica Cooper, Junichi Yamagishi, Tomoki Toda
ICASSP 2022, May, 2022
	  
<b>Generalization Ability of MOS Prediction Networks.</b> 
Erica Cooper, Wen-Chin Huang, Tomoki Toda, Junichi Yamagishi
ICASSP 2022, May, 2022
	  
<b>Use of Speaker Recognition Approaches for Learning and Evaluating Embedding Representations of Musical Instrument Sounds.</b> 
Xuan Shi, Erica Cooper, Junichi Yamagishi
IEEE/ACM Transactions on Audio, Speech, and Language Processing, 30 367-377, Jan, 2022
	  
<b>Multi-task learning in utterance-level and segmental-level spoof detection.</b> 
Lin Zhang, Xin Wang, Erica Cooper, Junichi Yamagishi
ASVspoof 2021, Sep, 2021
	  
<b>An Initial Investigation for Detecting Partially Spoofed Audio.</b> 
Lin Zhang, Xin Wang, Erica Cooper, Junichi Yamagishi, Jose Patino, Nicholas Evans
Interspeech 2021, Sep, 2021
	  
<b>How do Voices from Past Speech Synthesis Challenges Compare Today?</b> 
Erica Cooper, Junichi Yamagishi
11th ISCA Speech Synthesis Workshop, Aug, 2021
	  
<b>Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis.</b> 
Erica Cooper, Xin Wang, Junichi Yamagishi
11th ISCA Speech Synthesis Workshop, Aug, 2021
	  
<b>Exploring Disentanglement with Multilingual and Monolingual VQ-VAE.</b> 
Jennifer Williams, Jason Fong, Erica Cooper, Junichi Yamagishi
11th ISCA Speech Synthesis Workshop, Aug, 2021
	  
<b>Learning Disentangled Phone and Speaker Representations in a Semi-Supervised VQ-VAE Paradigm.</b> 
Jennifer Williams, Yi Zhao, Erica Cooper, Junichi Yamagishi
ICASSP 2021, Jun, 2021
	  
<b>How Similar or Different Is Rakugo Speech Synthesizer to Professional Performers?</b> 
Shuhei Kato, Yusuke Yasuda, Xin Wang, Erica Cooper, Junichi Yamagishi
ICASSP 2021, Jun, 2021
	  
<b>Improved Prosody from Learned F0 Codebook Representations for VQ-VAE Speech Waveform Reconstruction.</b> 
Yi Zhao, Haoyu Li, Cheng-I Lai, Jennifer Williams, Erica Cooper, Junichi Yamagishi
Interspeech 2020, Oct, 2020

<b>Can Speaker Augmentation Improve Multi-Speaker End-to-End TTS?</b>
Erica Cooper, Cheng-I Lai, Yusuke Yasuda, Junichi Yamagishi
Interspeech 2020, Oct, 2020

<b>Zero-Shot Multi-Speaker Text-To-Speech with State-of-the-art Neural Speaker Embeddings.</b> 
Erica Cooper, Cheng-I Lai, Yusuke Yasuda, Fuming Fang, Xin Wang, Nanxin Chen, Junichi Yamagishi
ICASSP 2020, May, 2020

<b>Modeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis That Entertains Audiences.</b> 
Shuhei Kato, Yusuke Yasuda, Xin Wang, Erica Cooper, Shinji Takaki, Junichi Yamagishi
IEEE Access, 8 138149-138161, 2020

<b>Subset Selection, Adaptation and Gemination for Amharic Text-to-Speech Synthesis.</b> 
Elshadai Tesfaye Biru, Yishak Tofik Mohammed, David Tofu, Erica Cooper, Julia Hirschberg
10th ISCA Speech Synthesis Workshop (SSW10), Sep, 2019
	  
<b>Rakugo speech synthesis using segment-to-segment neural transduction and style tokens — toward speech synthesis for entertaining audiences.</b> 
Shuhei Kato, Yusuke Yasuda, Xin Wang, Erica Cooper, Shinji Takaki, Junichi Yamagishi
10th ISCA Speech Synthesis Workshop (SSW10), Sep, 2019

    		<b>A Comparison of Speaker-based and Utterance-based
		Data Selection for Text-to-Speech Synthesis.</b>
		 Kai-Zhan Lee, Erica Cooper, Julia Hirschberg.
		  Interspeech, September 2018, Hyderabad, India.<br>
	<!-- 	  <div class="dls">
		    <a href=http://www.cs.columbia.edu/speech/PaperFiles/2018/lee_is18.pdf
		    target="_blank"> <i class="fa fa-file-pdf-o" ></i>
		    <span class="underline">paper</span>
		    <a href="is18poster.pdf"
		    target="_blank"><i class="fa fa-file-pdf-o"></i>
		    <span class="underline">poster</span></a>  -->
		  </div>
	  <p>

		<b>Adaptation and Frontend Features to Improve
		Naturalness in Found-Data Synthesis.</b>
		Erica Cooper, Julia Hirschberg.
		  Speech Prosody, June 2018, Poznań, Poland.<br>
	<!--	  <div class="dls">
		    <a href="sp18-thirds.pdf"
		    target="_blank"><i class="fa fa-file-pdf-o" ></i>
		    <span class="underline">paper</span>
		    <a href="sp2018slides.pdf"
		    target="_blank"><i class="fa fa-file-pdf-o"></i>
		    <span class="underline">slides</span></a>
		  </div>  -->
		  <p>

	      <div role="tabpanel" class="tab-pane" id="publications">

		<b>Characteristics of Text-to-Speech and Other Corpora.</b>
		Erica Cooper, Emily Li, Julia Hirschberg.
		  Speech Prosody, June 2018, Poznań, Poland.<br>
	<!--	  <div class="dls">
		    <a href="SP18_paper_180.pdf"
		    target="_blank"><i class="fa fa-file-pdf-o"></i>
		    <span class="underline">paper</span></a>
		    <a href="sp2018poster.pdf"
		    target="_blank"><i class="fa fa-file-pdf-o"></i>
		    <span class="underline">poster</span></a>
		  </div>    -->
		      <p>

		<b>Utterance Selection for Optimizing Intelligibility
		of TTS Voices Trained on ASR Data.</b>
		Erica Cooper, Xinyue Wang, Alison Chang, Yocheved
		Levitan, Julia Hirschberg.
		  Interspeech, August 2017, Stockholm, Sweden.<br>
	<!--	  <div class="dls">
		    <a href="is2017-final.pdf"
		    target="_blank"><i class="fa fa-file-pdf-o"></i>
		    <span class="underline">paper</span></a>
		    <a href="is2017poster.pdf"
		    target="_blank"><i class="fa fa-file-pdf-o"></i>
		    <span class="underline">poster</span></a>
		  </div>  -->
			      <p>

		<b>Data Selection and Adaptation for Naturalness in
		HMM-based Speech Synthesis.</b>
		Erica Cooper, Alison Chang, Yocheved Levitan, Julia Hirschberg.
		  Interspeech, September 2016, San
		  Francisco, California.<br> 
	<!--	  <div class="dls">
		    <a href="datasel-final.pdf" target="_blank"><i class="fa
		    fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		    <a href="Interspeech_Sept2016_CU_Cooper.pdf" target="_blank"><i class="fa
		    fa-file-pdf-o"></i> <span class="underline">poster</span></a> 
		    </div>    -->

		</p>

		<b>Babler - Data Collection from the Web to Support
           Speech Recognition and Keyword Search.</b>
		Gideon Mendels, Erica Cooper, Julia Hirschberg.
		  10th Web as Corpus Workshop (WAC-X), August 2016,
		  Berlin, Germany.<br> 
	<!--	  <div class="dls">
		    <a href="babler-data-collection.pdf" target="_blank"><i class="fa
		    fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		    <a href="babler-data-collection-poster.pdf" target="_blank"><i class="fa
		    fa-file-pdf-o"></i> <span class="underline">poster</span></a> 
		    </div>   -->
		</p>

		<b>Data Selection for Naturalness in HMM-based Speech
		Synthesis.</b>
		Erica Cooper, Yocheved Levitan, Julia Hirschberg.
		  Speech Prosody, June 2016, Boston,
		  Massachusetts.<br> 
	<!--	<div class="dls">
		<a href="sp2016.pdf" target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		<a href="poster-sp2016.pdf"
		target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">poster</span></a>
		</div>  -->
		</p>

		<b>Improving Speech Recognition and Keyword Search
		for Low Resource Languages Using Web Data.</b>
		Gideon Mendels, Erica Cooper, Victor Soto, Julia
		  Hirschberg, Mark Gales, Kate Knill, Anton Ragni,
		  Haipeng Wang.  Interspeech, September 2015, Dresden,
		  Germany.<br> 
	<!--	  <div class="dls">
		    <a href="http://www.cs.columbia.edu/speech/PaperFiles/2015/webdata_interspeech_2015.pdf" target="_blank"><i class="fa
		fa-file-pdf-o"></i><span class="underline">paper</span></a>
		</div>    -->
		</p>

		<b>Rescoring Confusion Networks for Keyword
		Search.</b> 
		Victor Soto, Erica Cooper, Lidia Mangu,
		Andrew Rosenberg, Julia Hirschberg. Victor Soto, Erica
		Cooper, Lidia Mangu, Andrew Rosenberg, Julia
		Hirschberg.  International Conference on Acoustics,
		Speech and Signal Processing, May 2014, Florence, Italy.<br>
	<!--	<div class="dls">
		<a href="p7138-soto.pdf" target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		<a href="prosody_icassp14_poster.pdf"
		target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">poster</span></a>
		</div>   -->
		</p>

		<b>Cross-Language Phrase Boundary Detection.</b>
		Victor Soto, Erica Cooper, Andrew Rosenberg, Julia
		Hirschberg.  International Conference on Acoustics,
		Speech and Signal Processing, May 2013, Vancouver,
		Canada.<br>
	<!--	<div class="dls">
		<a href="soto-Columbia-icassp13-v2.pdf"
		target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		<a href="poster-surf-5a.pdf"
		target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">poster</span></a>
		</div>   -->
		</p>

		<b>Cross-Language Prominence Detection.</b>
		Andrew
		Rosenberg, Erica Cooper, Rivka Levitan, Julia
		Hirschberg.  Speech Prosody, May 2012, Shanghai,
		China.<br>
	<!--	<div class="dls">
		<a href="sp2012_submission_97.pdf"
		target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		<a href="sp2012-slides.pdf"
		target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">slides</span></a>
		</div>   -->
		</p>

		<b>Effect of Pronunciations on OOV Queries in
		Spoken Term Detection.</b>
		Dogan Can, Erica Cooper,
		Abhinav Sethy, Chris White, Bhuvana Ramabhadran, Murat
		Saraclar.  International Conference on Acoustics,
		Speech and Signal Processing, April 2009, Taipei,
		Taiwan.<br>
	<!--	<div class="dls">
		<a href="04960494.pdf" target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		</div>     -->
		</p>

		<b>Unsupervised Pronunciation Validation.</b>
		
		Christopher M. White, Abhinav Sethy, Bhuvana
		Ramabhadran, Patrick Wolfe, Erica Cooper, Murat
		Saraclar, James K. Baker.  International Conference on
		Acoustics, Speech and Signal Processing, April 2009,
		Taipei, Taiwan.<br>
	<!--	<div class="dls">
		<a href="white09.pdf" target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		</div>    -->
		</p>

		<b>Web-derived Pronunciations for Spoken Term
		Detection.</b>
		Dogan Can, Erica Cooper, Arnab
		Ghoshal, Martin Jansche, Sanjeev Khudanpur, Bhuvana
		Ramabhadran, Michael Riley, Murat Saraclar, Abhinav
		Sethy, Morgan Ulinski, Christopher White.  Special
		Interest Group on Information Retrieval, July 2009,
		Boston, Massachusetts. <br>
	<!--	<div class="dls">
		<a href="canetal09b.pdf" target="_blank"><i class="fa
		fa-file-pdf-o"></i> <span class="underline">paper</span></a>
		</div>   -->
		</p>

<!--    <h3>Grants received</h3>   -->

    
  </body>
</html>
